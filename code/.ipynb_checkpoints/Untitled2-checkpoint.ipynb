{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn # this changes matplotlib defaults to make the graphs look cooler!\n",
    "import pickle \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, scale\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# load contracts data\n",
    "contracts = pd.read_csv('../Data/Procurements/awards_with_features.csv', index_col=0, low_memory=False)\n",
    "\n",
    "# load network features\n",
    "network_country = pd.read_csv('../Data/Procurements/Historic_and_Major_awards_network_features_Country2.csv', index_col=0, low_memory=False)\n",
    "network_global = pd.read_csv('../Data/Procurements/Historic_and_Major_awards_network_features.csv', index_col=0, low_memory=False)\n",
    "\n",
    "# kick out contracts with no supplier to match\n",
    "contracts = contracts[contracts['canonical_name'].notnull()]\n",
    "\n",
    "# load investigations\n",
    "investigations = pd.read_csv('../Data/Investigations/investigations.csv', index_col=0, low_memory=False)\n",
    "investigations['guilty_or_unknown'] = \\\n",
    "  np.logical_and(  investigations.outcome_of_overall_investigation_when_closed.notnull(), \\\n",
    "                investigations.outcome_of_overall_investigation_when_closed != 'Unfounded') \n",
    "\n",
    "# this should assign True = Investigated, False = Otherwise\n",
    "\n",
    "# group by canonical_name and country to remove duplicates\n",
    "def reduce_to_one(my_list):\n",
    "    return my_list.unique()\n",
    "\n",
    "aggregations = {\n",
    "    'guilty_or_unknown':'sum',\n",
    "    'unique_id': reduce_to_one\n",
    "}\n",
    "investigations = investigations.groupby(by=['canonical_name', 'country'], as_index=False).agg(aggregations)\n",
    "\n",
    "# drop investigations that where outcome of overall investigation is Unfounded or missing\n",
    "investigations = investigations[investigations['guilty_or_unknown'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_global_features = network_global.columns[78:].tolist()\n",
    "net_global_features.extend(['unique_id'])\n",
    "network_global = network_global[net_global_features]\n",
    "\n",
    "net_country_features = network_country.columns[4:].tolist()\n",
    "network_country = network_country[net_country_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create full data set\n",
    "df = pd.merge(left=contracts,\n",
    "                   right=investigations,  \n",
    "                   left_on=['canonical_name', 'buyer_country'], #, 'fiscal_year'],\n",
    "                   right_on=['canonical_name', 'country'], #, 'fy_complaint_opened'],\n",
    "                   how='left') # this makes sure that we keep all procuremenets, whether they have a matching investigation or not\n",
    "\n",
    "df.rename(columns={'unique_id_x':'unique_id_contracts', 'unique_id_y':'unique_id_invests'}, inplace=True)\n",
    "\n",
    "df = df.merge(right=network_global,\n",
    "              left_on='unique_id_contracts',\n",
    "              # left_on='unique_id',\n",
    "              right_on='unique_id')\n",
    "\n",
    "df = df.merge(right=network_country,\n",
    "              left_on='unique_id_contracts',\n",
    "              right_on='unique_id')\n",
    "del df['unique_id_x']\n",
    "del df['unique_id_y']\n",
    "del df['country']\n",
    "df['overlap'] = df['unique_id_invests'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "\n",
    "remove_list = [\n",
    "    'buyer',\n",
    "    #'buyer_country',\n",
    "    #'project_id',\n",
    "    #'unique_id_contracts',\n",
    "    'unique_id_invests',\n",
    "    #'major_sector_clean',\n",
    "    #'canonical_name',\n",
    "    'guilty_or_unknown',\n",
    "    'Supplier_Average_Distance_Investigated_Suppliers_Contemporary_Global',\n",
    "    'Project_Average_Distance_Investigated_Suppliers_Contemporary_Global',\n",
    "    'Supplier_Average_Distance_Investigated_Suppliers_Cumulative_Global',\n",
    "    'Project_Average_Distance_Investigated_Suppliers_Cumulative_Global',\n",
    "    'Supplier_Average_Distance_Investigated_Projects_Contemporary_Global',\n",
    "    'Project_Average_Distance_Investigated_Projects_Contemporary_Global',\n",
    "    'Supplier_Average_Distance_Investigated_Projects_Cumulative_Global',\n",
    "    'Project_Average_Distance_Investigated_Projects_Cumulative_Global',\n",
    "    'Supplier_Average_Distance_Investigated_Suppliers_Contemporary_Country',\n",
    "    'Project_Average_Distance_Investigated_Suppliers_Contemporary_Country',\n",
    "    'Supplier_Average_Distance_Investigated_Suppliers_Cumulative_Country',\n",
    "    'Project_Average_Distance_Investigated_Suppliers_Cumulative_Country',\n",
    "    'Supplier_Average_Distance_Investigated_Projects_Contemporary_Country',\n",
    "    'Project_Average_Distance_Investigated_Projects_Contemporary_Country',\n",
    "    'Supplier_Average_Distance_Investigated_Projects_Cumulative_Country',\n",
    "    'Project_Average_Distance_Investigated_Projects_Cumulative_Country',\n",
    "    'Supplier_Degree_Centrality_Contemporary_Country',\n",
    "    'Supplier_Degree_Centrality_Cumulative_Country',\n",
    "    'Supplier_Degree_Centrality_Contemporary_Global',\n",
    "    'Supplier_Degree_Centrality_Cumulative_Global'\n",
    "]\n",
    "for feature in remove_list:\n",
    "    features.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'award_amount_usd', u'buyer_country', u'competitive', u'fiscal_year', u'number_of_bids', u'project_id', u'unique_id_contracts', u'major_sector_clean', u'canonical_name', u'business_disclosure_index_nearest', u'firms_competing_against_informal_firms_perc_nearest', u'payments_to_public_officials_perc_nearest', u'do_not_report_all_sales_perc_nearest', u'legal_rights_index_nearest', u'time_to_enforce_contract_nearest', u'bribes_to_tax_officials_perc_nearest', u'property_rights_rule_governance_rating_nearest', u'transparency_accountability_corruption_rating_nearest', u'gdp_per_capita_nearest', u'primary_school_graduation_perc_nearest', u'gini_index_nearest', u'unemployment_perc_nearest', u'gdp_per_capita_perc_change_1', u'gdp_per_capita_perc_change_5', u'gdp_per_capita_mean', u'number_of_sectors_CY', u'number_of_suppliers_CY', u'perc_competitive_CY', u'number_of_buyers_CY', u'number_of_bids_CY', u'number_of_projects_CY', u'number_of_contracts_CY', u'award_amount_usd_CY', u'number_of_bids_C_perc_change_1yr', u'number_of_bids_C_perc_change_5yr', u'number_of_bids_C', u'number_of_bids_C_annual_mean', u'award_amount_usd_C_perc_change_1yr', u'award_amount_usd_C_perc_change_5yr', u'award_amount_usd_C', u'award_amount_usd_C_annual_mean', u'number_of_contracts_C_perc_change_1yr', u'number_of_contracts_C_perc_change_5yr', u'number_of_contracts_C', u'number_of_contracts_C_annual_mean', u'number_of_bids_S_perc_change_1yr', u'number_of_bids_S_perc_change_5yr', u'number_of_bids_S', u'number_of_bids_S_annual_mean', u'award_amount_usd_S_perc_change_1yr', u'award_amount_usd_S_perc_change_5yr', u'award_amount_usd_S', u'award_amount_usd_S_annual_mean', u'number_of_contracts_S_perc_change_1yr', u'number_of_contracts_S_perc_change_5yr', u'number_of_contracts_S', u'number_of_contracts_S_annual_mean', u'number_of_bids_CS_perc_change_1yr', u'number_of_bids_CS_perc_change_5yr', u'number_of_bids_CS', u'number_of_bids_CS_annual_mean', u'award_amount_usd_CS_perc_change_1yr', u'award_amount_usd_CS_perc_change_5yr', u'award_amount_usd_CS', u'award_amount_usd_CS_annual_mean', u'number_of_contracts_CS_perc_change_1yr', u'number_of_contracts_CS_perc_change_5yr', u'number_of_contracts_CS', u'number_of_contracts_CS_annual_mean', u'number_of_sectors_P', u'number_of_suppliers_P', u'perc_competitive_P', u'number_of_buyers_P', u'number_of_bids_P', u'number_of_countries_P', u'number_of_contracts_P', u'award_amount_usd_P', u'award_amount_usd_per_contract_P', u'number_of_bids_per_contract_P', u'number_of_sectors_SuppY', u'number_of_projects_SuppY', u'perc_competitive_SuppY', u'number_of_buyers_SuppY', u'number_of_bids_SuppY', u'number_of_countries_SuppY', u'number_of_contracts_SuppY', u'award_amount_usd_SuppY', u'number_of_contracts_Supp', u'number_of_contracts_Supp_annual_mean', u'award_amount_usd_Supp', u'award_amount_usd_Supp_annual_mean', u'number_of_bids_SuppCY', u'perc_competitive_SuppCY', u'number_of_sectors_SuppCY', u'number_of_buyers_SuppCY', u'number_of_projects_SuppCY', u'number_of_contracts_SuppCY', u'award_amount_usd_SuppCY', u'number_of_contracts_SuppC', u'number_of_contracts_SuppC_annual_mean', ...], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#remove project-supplier and supplier-project features\n",
    "remove_list = []\n",
    "for col in features:\n",
    "    if 'Project' in col and 'Supplier' in col:\n",
    "       remove_list.append(col)\n",
    "\n",
    "for feature in remove_list: \n",
    "    features.remove(feature)\n",
    "\n",
    "#remove all \"distance to investigated\" features\n",
    "remove_list = []\n",
    "for col in features:\n",
    "    if 'Investigated' in col:\n",
    "       remove_list.append(col)\n",
    "\n",
    "for feature in remove_list: \n",
    "    features.remove(feature)\n",
    "\n",
    "df2 = df[features]\n",
    "\n",
    "\n",
    "# Select features\n",
    "features = df2.columns.tolist()\n",
    "remove_list = [\n",
    "    'buyer_country',\n",
    "    'project_id',\n",
    "    'unique_id_contracts',\n",
    "    'major_sector_clean',\n",
    "    'canonical_name'\n",
    "]\n",
    "\n",
    "for feature in remove_list: \n",
    "    features.remove(feature)\n",
    "\n",
    "zero_nan_cols = [\n",
    "    'Supplier_Neighbor_Intensity_Contemporary_Global',\n",
    "    'Project_Neighbor_Intensity_Contemporary_Global',\n",
    "    'Supplier_Neighbor_Intensity_Cumulative_Global',\n",
    "    'Project_Neighbor_Intensity_Cumulative_Global',\n",
    "    'Supplier_Neighbor_Intensity_Contemporary_Country',\n",
    "    'Project_Neighbor_Intensity_Contemporary_Country',\n",
    "    'Supplier_Neighbor_Intensity_Cumulative_Country',\n",
    "    'Project_Neighbor_Intensity_Cumulative_Country'\n",
    "]\n",
    "\n",
    "df2[zero_nan_cols] = df2[zero_nan_cols].fillna(value=0)\n",
    "print df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float64' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-ccb312df729c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'float64' is not defined"
     ]
    }
   ],
   "source": [
    "mean_nan_cols = df2[features].columns.tolist()\n",
    "for col in mean_nan_cols:\n",
    "    mean = df2[col].mean()\n",
    "    df2[col] = df2[col].fillna(value=mean)\n",
    "    \n",
    "#for col in df2[features].columns:\n",
    "#    df2[col] = df2[col].astype()\n",
    "\n",
    "for col in df2[features].columns:\n",
    "    df2[col][np.isinf(df2[col])] = -1\n",
    "    df2[col].replace(-1, max(df2[col])*1.1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "random_inds = sample(df[~(df['overlap'].astype(bool))].index.values, 4000)\n",
    "df_nonoverlap_random = df[features].ix[random_inds]\n",
    "df_overlap = df[features][df['overlap'].astype(bool)]\n",
    "full_data = df_overlap.append(df_nonoverlap_random, ignore_index=True)\n",
    "\n",
    "# Sort by year\n",
    "full_data = full_data.sort('fiscal_year')\n",
    "del full_data['fiscal_year']\n",
    "labels = full_data['overlap']\n",
    "del full_data['overlap']\n",
    "\n",
    "for col in full_data.columns:\n",
    "    full_data[col][ np.isinf(full_data[col])] = -1\n",
    "    full_data[col].replace(-1, max(full_data[col])*1.1, inplace=True)\n",
    "\n",
    "# df_overlap.shape\n",
    "X_train, X_test = full_data[:-2000].as_matrix(), full_data[-2000:].as_matrix()\n",
    "y_train, y_test = labels[:-2000].as_matrix(), labels[-2000:].as_matrix()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for roc_auc\n",
      "---------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-2ab7420785a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrf_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cross-validation takes a while!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on training set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# #Random Forest\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [{\n",
    "#     'max_features':[None, 'auto'],\n",
    "#     'max_depth':[None, sqrt(len(features))],\n",
    "    'n_estimators': [100] # of these, the more the better\n",
    "}] \n",
    "\n",
    "scores = ['roc_auc']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print('---------------')\n",
    "    rf_clf = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring=score) # cross-validation takes a while!!!\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print(rf_clf.best_estimator_)\n",
    "    print('---')\n",
    "    \n",
    "    print(\"Grid scores on development set:\")\n",
    "    for params, mean_score, scores in rf_clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "    print('---')\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(classification_report(y_test, rf_clf.predict(X_test)))\n",
    "\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "pd.Series(y_pred).value_counts()\n",
    "\n",
    "\n",
    "for ind in argsort(rf_clf.best_estimator_.feature_importances_)[::-1]:\n",
    "    print '%0.2f' % rf_clf.best_estimator_.feature_importances_[ind], features[ind]\n",
    "\n",
    "\n",
    "feature_importances = []\n",
    "for ind in argsort(rf_clf.best_estimator_.feature_importances_)[::-1]:\n",
    "    feature_importances.append([features[ind], rf_clf.best_estimator_.feature_importances_[ind]])\n",
    "feature_importances = pd.DataFrame(feature_importances)\n",
    "feature_importances.columns = ['feature','importance']\n",
    "\n",
    "percent_missing = pd.DataFrame(percent_missing)\n",
    "percent_missing.columns = ['feature', 'percent_missing']\n",
    "\n",
    "feature_df = pd.merge(feature_importances, percent_missing, on='feature', how='left')\n",
    "\n",
    "\n",
    "scatter(feature_df['importance'], feature_df['percent_missing'])\n",
    "\n",
    "\n",
    "feature_importances.shape\n",
    "\n",
    "\n",
    "# Generate ROC curve\n",
    "# Compute ROC curve and area under the curve\n",
    "rf_probs = rf_clf.best_estimator_.predict_proba(X_test)\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf_probs[:, 1])\n",
    "rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "# Compute ROC curve and area the curve\n",
    "# svm_probs = svm.best_estimator_.predict_proba(X_train)\n",
    "# svm_fpr, svm_tpr, svm_thresholds = roc_curve(y_train, svm_probs[:, 1])\n",
    "# svm_roc_auc = auc(svm_fpr, svm_tpr)\n",
    "# rf_probs = rf.best_estimator_.predict_proba(X_train)\n",
    "# rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_train, rf_probs[:, 1])\n",
    "# rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.clf()\n",
    "plt.plot(rf_fpr, rf_tpr, label='Random Forest (auc = %0.2f)' % rf_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('% Uninvestigated Contracts Marked as \"Should be investigated\"')\n",
    "plt.ylabel('% Investigated Contracts Caught by Model')\n",
    "plt.title('True Positive Rate vs. False Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Generate precision-recall curve\n",
    "rf_probs = rf_clf.best_estimator_.predict_proba(X_test)\n",
    "rf_precision, rf_recall, rf_thresholds = precision_recall_curve(y_test, rf_probs[:, 1])\n",
    "#rf_PR_auc = auc(rf_precision, rf_recall, reorder=True)\n",
    "\n",
    "# Compute ROC curve and area the curve\n",
    "# svm_probs = svm.best_estimator_.predict_proba(X_train)\n",
    "# svm_fpr, svm_tpr, svm_thresholds = roc_curve(y_train, svm_probs[:, 1])\n",
    "# svm_roc_auc = auc(svm_fpr, svm_tpr)\n",
    "# rf_probs = rf.best_estimator_.predict_proba(X_train)\n",
    "# rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_train, rf_probs[:, 1])\n",
    "# rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "# Plot precision_recall curve\n",
    "plt.clf()\n",
    "plt.plot( rf_recall, rf_precision, label='Random Forest')\n",
    "plt.plot([1, 0], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.1])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
